{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop-Shipping Listings Classification Project - TF_IDF, Word2Vec, and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T15:18:46.994147900Z",
     "start_time": "2023-12-14T15:18:36.331270Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing needed packages \n",
    "import pandas as pd \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import nltk\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T15:18:47.148026700Z",
     "start_time": "2023-12-14T15:18:46.994147900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Text from listing  label\n",
      "0   skip main content walmart depart servic search...      0\n",
      "1   christma saber giveaway four zero off all sabe...      0\n",
      "2   dure black novemb youv donat four zero zero ze...      0\n",
      "3   v skip main content ebay home shop categori en...      0\n",
      "4   skip content shop our holiday gift guid to fin...      0\n",
      "..                                                ...    ...\n",
      "94  jameco electron product search enter product w...      0\n",
      "95  jameco electron product search enter product w...      0\n",
      "96  jameco electron product search enter product w...      0\n",
      "97  jameco electron product search enter product w...      0\n",
      "98  jameco electron product search enter product w...      0\n",
      "\n",
      "[300 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Handling DROP-SHIPPING data\n",
    "file_path1 = 'Data Scraping/LightSabers_DS_Processed.csv'\n",
    "file_path2 = 'Data Scraping/StripLights_DS_Processed.csv'\n",
    "file_path3 = 'Data Scraping/PowerAdapters_DS_Processed.csv'\n",
    "df_1 = pd.read_csv(file_path1, header=None)\n",
    "df_2 = pd.read_csv(file_path2, header=None)\n",
    "df_3 = pd.read_csv(file_path3, header=None)\n",
    "\n",
    "# Create combined dataframe\n",
    "ds_df = pd.concat([df_1, df_2, df_3])\n",
    "\n",
    "# Set header\n",
    "ds_df.columns = ['Text from listing']\n",
    "ds_df['label'] = 0\n",
    "print(ds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T15:18:52.375825700Z",
     "start_time": "2023-12-14T15:18:52.252635800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Handling NON DROP-SHIPPING data\n",
    "# Function to read and process a text file\n",
    "def read_and_process_file(filename):\n",
    "    with open(filename, 'r', encoding = 'utf-8') as file:\n",
    "        data = file.read().split('\\n')  # Splitting by line break\n",
    "    return data\n",
    "\n",
    "# File names\n",
    "file_names = ['Data Scraping/lightsaber_non_DS.txt', 'Data Scraping/poweradapters_non_DS.txt', 'Data Scraping/striplights_non_DS.txt']\n",
    "\n",
    "# Reading and processing all files\n",
    "all_data = []\n",
    "for file in file_names:\n",
    "    data = read_and_process_file(file)\n",
    "    all_data.extend(data)\n",
    "\n",
    "# Converting to a DataFrame\n",
    "non_ds_df = pd.DataFrame(all_data, columns=['Text from listing'])\n",
    "non_ds_df['label'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T15:18:56.386664900Z",
     "start_time": "2023-12-14T15:18:56.338664200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      Text from listing  label\n",
      "0     aliexpress aliexpresscom onlin shop automot ph...      1\n",
      "1     huawei supercharg cabl originaladapt huawei su...      1\n",
      "2     one six color rgbretractabletwo one flash ligh...      1\n",
      "3     skip content saberforg saber adapt saber part ...      0\n",
      "4     dark saber lightsaberdark saber bladelightsab ...      1\n",
      "...                                                 ...    ...\n",
      "3012  aliexpress aliexpresscom onlin shop automot ph...      1\n",
      "3013  aliexpress aliexpresscom onlin shop automot ph...      1\n",
      "3014  usb c fast charger mobil phone charger mobil p...      1\n",
      "3015  aliexpress aliexpresscom onlin shop automot ph...      1\n",
      "3016  aliexpress aliexpresscom onlin shop automot ph...      1\n",
      "\n",
      "[3017 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# COMBINING DFs\n",
    "combined_df = pd.concat([ds_df, non_ds_df])\n",
    "\n",
    "\n",
    "# Shuffling combined DF in order to aid randomness\n",
    "combined_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "outputs": [],
   "source": [
    "# with open('combined_training_set.csv', 'w', encoding = 'utf-8') as csv_file:\n",
    "#\n",
    "#     header = ','.join(combined_df.columns) + '\\n'\n",
    "#     csv_file.write(header)\n",
    "#\n",
    "#\n",
    "#     for index, row in combined_df.iterrows():\n",
    "#         row_str = ','.join(map(str, row.values)) + '\\n'\n",
    "#         csv_file.write(row_str)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T03:50:40.401479500Z",
     "start_time": "2023-12-14T03:50:40.090348900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T15:19:00.062092Z",
     "start_time": "2023-12-14T15:18:59.973003600Z"
    }
   },
   "outputs": [],
   "source": [
    "### Splitting dataframe into training, development and test:\n",
    "# combined_df = pd.read_csv('combined_training_set.csv')\n",
    "# combined_df = pd.read_csv('combined_training_set.csv')\n",
    "# print(combined_df)\n",
    "# Splitting the data into training (70%) and a temporary set (30%)\n",
    "train_df, temp_df = train_test_split(combined_df, test_size=0.3, stratify=combined_df['label'], random_state=42)\n",
    "\n",
    "# Splitting the temporary set into development and test sets (each 15% of the original data)\n",
    "dev_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['label'], random_state=42)\n",
    "\n",
    "y_train = train_df['label'].values\n",
    "y_dev = dev_df['label'].values\n",
    "y_test = test_df['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T15:19:07.057061100Z",
     "start_time": "2023-12-14T15:19:05.997256900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exclude the label column and then combine the rest\n",
    "# preprocessed_df['combined_text'] = preprocessed_df.drop('label', axis=1).apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(train_df['Text from listing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T15:19:07.408148700Z",
     "start_time": "2023-12-14T15:19:07.058674300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transform the Development and Test Sets:\n",
    "X_dev_tfidf = tfidf_vectorizer.transform(dev_df['Text from listing'])\n",
    "X_test_tfidf = tfidf_vectorizer.transform(test_df['Text from listing'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression - Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T15:19:14.508724300Z",
     "start_time": "2023-12-14T15:19:14.473645500Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T15:19:16.988249600Z",
     "start_time": "2023-12-14T15:19:16.612859800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegression()",
      "text/html": "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LR = LogisticRegression()\n",
    "model_LR.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Stratified CV (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T16:05:12.829036600Z",
     "start_time": "2023-12-14T16:05:12.775513200Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "number_of_folds = 3\n",
    "skf = StratifiedKFold(n_splits=number_of_folds, random_state=42, shuffle=True)\n",
    "model_LR2 = LogisticRegression(class_weight=\"balanced\")\n",
    "model_LR3 = LogisticRegression()\n",
    "model_LR4 = LogisticRegression(C=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T16:05:13.298332600Z",
     "start_time": "2023-12-14T16:05:13.234787900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combining TRAINING and DEVELOPMENT sets to perform Stratified Cross-Validation\n",
    "train_dev_df = pd.concat([train_df, dev_df])\n",
    "X_train_dev = train_dev_df\n",
    "y_train_dev = train_dev_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T16:13:43.405078300Z",
     "start_time": "2023-12-14T16:13:39.114663500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The evaluation metrics for model LogisticRegression(class_weight='balanced') are as follows:\n",
      "Average Accuracy: 0.9434510684726387\n",
      "Average Precision. DS: 0.9461421946333392, Non DS: 0.9432072954678604\n",
      "Average Recall. DS: 0.6502707382165465, Non DS: 0.9935946861374254\n",
      "Average F1 Score. DS: 0.7707339901393001, Non DS: 0.9677433903005145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [model_LR2]\n",
    "final_model = model_LR2\n",
    "X_test_tfidf_2 = X_test_tfidf\n",
    "for model in models: \n",
    "    accuracies = []\n",
    "    precisions_DS = []\n",
    "    precisions_non_DS = []\n",
    "    recalls_DS= []\n",
    "    recalls_non_DS= []\n",
    "    f1_scores_DS = []\n",
    "    f1_scores_non_DS = []\n",
    "\n",
    "    for train_index, val_index in skf.split(X_train_dev, y_train_dev):\n",
    "\n",
    "        # Splitting the data into train and validation for this fold\n",
    "        X_train_fold, X_val_fold = X_train_dev.iloc[train_index], X_train_dev.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_train_dev.iloc[train_index], y_train_dev.iloc[val_index]\n",
    "\n",
    "        # Applying TF-IDF transformation within each fold\n",
    "        tfidf_vectorizer = TfidfVectorizer()\n",
    "        X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_fold['Text from listing'])\n",
    "        X_val_tfidf = tfidf_vectorizer.transform(X_val_fold['Text from listing'])\n",
    "        X_test_tfidf_2 = tfidf_vectorizer.transform(test_df['Text from listing'])\n",
    "\n",
    "        # Fit the model\n",
    "        model.fit(X_train_tfidf, y_train_fold)\n",
    "        final_model = model\n",
    "\n",
    "        # Predict and evaluate on the validation data\n",
    "        predictions = model.predict(X_val_tfidf)\n",
    "\n",
    "        # Evaluate the model\n",
    "        accuracy = accuracy_score(y_val_fold, predictions)\n",
    "        precision = precision_score(y_val_fold, predictions, average=None)\n",
    "        recall = recall_score(y_val_fold, predictions, average=None)\n",
    "        f1 = f1_score(y_val_fold, predictions, average=None)\n",
    "\n",
    "        accuracies.append(accuracy)\n",
    "        precisions_DS.append(precision[0])\n",
    "        precisions_non_DS.append(precision[1])\n",
    "        recalls_DS.append(recall[0])\n",
    "        recalls_non_DS.append(recall[1])\n",
    "        f1_scores_DS.append(f1[0])\n",
    "        f1_scores_non_DS.append(f1[1])\n",
    "        \n",
    "        #print(f\"Confusion Matrix:\\n{confusion_matrix(y_test_CV, predictions)}\")\n",
    "\n",
    "    average_accuracy = sum(accuracies) / len(accuracies)\n",
    "    average_precision = (sum(precisions_DS) / len(precisions_DS), sum(precisions_non_DS) / len(precisions_non_DS))\n",
    "    average_recall = (sum(recalls_DS) / len(recalls_DS), sum(recalls_non_DS) / len(recalls_non_DS))\n",
    "    average_f1_score = (sum(f1_scores_DS) / len(f1_scores_DS), sum(f1_scores_non_DS) / len(f1_scores_non_DS))\n",
    "\n",
    "    print(f\"The evaluation metrics for model {model} are as follows:\")\n",
    "    print(f\"Average Accuracy: {average_accuracy}\")\n",
    "    print(f\"Average Precision. DS: {average_precision[0]}, Non DS: {average_precision[1]}\")\n",
    "    print(f\"Average Recall. DS: {average_recall[0]}, Non DS: {average_recall[1]}\")\n",
    "    print(f\"Average F1 Score. DS: {average_f1_score[0]}, Non DS: {average_f1_score[1]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Stratified CV (Word2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T16:15:29.597724700Z",
     "start_time": "2023-12-14T16:15:28.242979700Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T16:15:29.621686100Z",
     "start_time": "2023-12-14T16:15:29.599307200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create helper function - Function to create averaged Word2Vec vectors\n",
    "def get_mean_vector(word2vec_model, words):\n",
    "    # Filter out words not in the vocabulary and compute mean vector\n",
    "    return np.mean([word2vec_model.wv[word] for word in words if word in word2vec_model.wv] or [np.zeros(word2vec_model.vector_size)], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T16:15:35.891089900Z",
     "start_time": "2023-12-14T16:15:31.303835200Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_dev['tokenized_text'] = X_train_dev['Text from listing'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model_LR2, model_LR3, model_LR4]\n",
    "\n",
    "for model in models: \n",
    "    accuracies = []\n",
    "    precisions_DS = []\n",
    "    precisions_non_DS = []\n",
    "    recalls_DS= []\n",
    "    recalls_non_DS= []\n",
    "    f1_scores_DS = []\n",
    "    f1_scores_non_DS = []\n",
    "\n",
    "    for train_index, val_index in skf.split(X_train_dev, y_train_dev):\n",
    "\n",
    "        # Splitting the data into train and validation for this fold\n",
    "        X_train_fold, X_val_fold = X_train_dev.iloc[train_index], X_train_dev.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_train_dev.iloc[train_index], y_train_dev.iloc[val_index]\n",
    "\n",
    "        # Train Word2Vec on the training part of the fold\n",
    "        word2vec_model = Word2Vec(X_train_fold['tokenized_text'], vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "        # Create Word2Vec feature vectors for training and validation data\n",
    "        X_train_vectors = np.array([get_mean_vector(word2vec_model, words) for words in X_train_fold['tokenized_text']])\n",
    "        X_val_vectors = np.array([get_mean_vector(word2vec_model, words) for words in X_val_fold['tokenized_text']])\n",
    "\n",
    "\n",
    "        # Fit the model\n",
    "        model.fit(X_train_vectors, y_train_fold)\n",
    "        \n",
    "\n",
    "        # Predict and evaluate on the validation data\n",
    "        predictions = model.predict(X_val_vectors)\n",
    "\n",
    "        # Evaluate the model\n",
    "        accuracy = accuracy_score(y_val_fold, predictions)\n",
    "        precision = precision_score(y_val_fold, predictions, average=None)\n",
    "        recall = recall_score(y_val_fold, predictions, average=None)\n",
    "        f1 = f1_score(y_val_fold, predictions, average=None)\n",
    "\n",
    "        accuracies.append(accuracy)\n",
    "        precisions_DS.append(precision[0])\n",
    "        precisions_non_DS.append(precision[1])\n",
    "        recalls_DS.append(recall[0])\n",
    "        recalls_non_DS.append(recall[1])\n",
    "        f1_scores_DS.append(f1[0])\n",
    "        f1_scores_non_DS.append(f1[1])\n",
    "        \n",
    "        #print(f\"Confusion Matrix:\\n{confusion_matrix(y_test_CV, predictions)}\")\n",
    "\n",
    "    average_accuracy = sum(accuracies) / len(accuracies)\n",
    "    average_precision = (sum(precisions_DS) / len(precisions_DS), sum(precisions_non_DS) / len(precisions_non_DS))\n",
    "    average_recall = (sum(recalls_DS) / len(recalls_DS), sum(recalls_non_DS) / len(recalls_non_DS))\n",
    "    average_f1_score = (sum(f1_scores_DS) / len(f1_scores_DS), sum(f1_scores_non_DS) / len(f1_scores_non_DS))\n",
    "\n",
    "    print(f\"The evaluation metrics for model {model} are as follows:\")\n",
    "    print(f\"Average Accuracy: {average_accuracy}\")\n",
    "    print(f\"Average Precision. DS: {average_precision[0]}, Non DS: {average_precision[1]}\")\n",
    "    print(f\"Average Recall. DS: {average_recall[0]}, Non DS: {average_recall[1]}\")\n",
    "    print(f\"Average F1 Score. DS: {average_f1_score[0]}, Non DS: {average_f1_score[1]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating on unseen test data (W2V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T16:56:40.650804600Z",
     "start_time": "2023-12-14T16:56:26.660441500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenizing data \n",
    "X_train_dev['tokenized_text'] = X_train_dev['Text from listing'].apply(word_tokenize)\n",
    "test_df['tokenized_text'] = test_df['Text from listing'].apply(word_tokenize)\n",
    "\n",
    "# Train Word2Vec on the training part\n",
    "word2vec_model = Word2Vec(X_train_dev['tokenized_text'], vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Create Word2Vec feature vectors for training and validation data\n",
    "X_train_vectors = np.array([get_mean_vector(word2vec_model, words) for words in X_train_dev['tokenized_text']])\n",
    "X_test_vectors = np.array([get_mean_vector(word2vec_model, words) for words in test_df['tokenized_text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T16:56:40.738803800Z",
     "start_time": "2023-12-14T16:56:40.650804600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\winst\\IdeaProjects\\NLP Final Project\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": "LogisticRegression(class_weight='balanced')",
      "text/html": "<style>#sk-container-id-16 {color: black;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;)</pre></div></div></div></div></div>"
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### DEFINING MODEL TO BE EVALUATED!!!\n",
    "y_train_dev = train_dev_df['label'].values\n",
    "\n",
    "# CHANGE THIS TO THE MODEL YOU WANT TO EVALUATE\n",
    "final_model1  = LogisticRegression(class_weight=\"balanced\")\n",
    "#final_model1  = LogisticRegression()\n",
    "# final_model1 = LogisticRegression(C=0.5)\n",
    "final_model1.fit(X_train_vectors, y_train_dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T16:58:28.915677Z",
     "start_time": "2023-12-14T16:58:28.886672300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The evaluation metrics for model LogisticRegression(class_weight='balanced') are as follows:\n",
      "Accuracy: 0.957\n",
      "Precision. DS: 0.945, Non DS: 0.974\n",
      "Recall. DS: 0.712, Non DS: 0.996\n",
      "F1 Score. DS: 0.809, Non DS: .985\n"
     ]
    }
   ],
   "source": [
    "### RUN THIS CODE TO GET FINAL EVALUATION!!!\n",
    "# Predict and evaluate on the test data\n",
    "predictions = final_model1.predict(X_test_vectors)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions, average=None)\n",
    "recall = recall_score(y_test, predictions, average=None)\n",
    "f1 = f1_score(y_test, predictions, average=None)\n",
    "\n",
    "print(f\"The evaluation metrics for model {final_model1} are as follows:\")\n",
    "print(f\"Accuracy: {accuracy: .3f}\")\n",
    "print(f\"Precision. DS: {precision[0]: .3f}, Non DS: {precision[1]: .3f}\")\n",
    "print(f\"Recall. DS: {recall[0]: .3f}, Non DS: {recall[1]: .3f}\")\n",
    "print(f\"F1 Score. DS: {f1[0]: .3f}, Non DS: {f1[1]: .3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
